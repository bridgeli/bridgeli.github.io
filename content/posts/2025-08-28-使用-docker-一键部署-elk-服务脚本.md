---
title: ä½¿ç”¨ docker ä¸€é”®éƒ¨ç½² ELK(åŒ…å«ä¸­æ–‡åˆ†è¯) æœåŠ¡è„šæœ¬
author: Bridge Li
type: post
date: 2025-08-28T09:26:14+00:00

categories:
  - Java
tags:
  - ElasticSearch
  - elasticsearch-analysis-ik
  - ELK
  - IKåˆ†è¯
  - kibana
  - Logstash

---
å‰å‡ å¤©å…¬å¸æœ‰ä¸ªéœ€æ±‚è¦åšå…¨æ–‡ç´¢å¼•ï¼Œäºæ˜¯å†™äº†ä¸€ä¸ªè„šæœ¬ä½¿ç”¨ docker ä¸€é”®éƒ¨ç½² ELK æœåŠ¡ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```

#!/bin/bash  
set -e

echo "=================================================="  
echo "ğŸš€ å¼€å§‹éƒ¨ç½² ELK + MySQL åŒæ­¥ï¼ˆä¸­æ–‡åˆ†è¯ + å›ºå®šç´¢å¼•ï¼‰"  
echo "=================================================="

\# ==================== é…ç½®åŒºï¼ˆè¯·ä¿®æ”¹ï¼‰====================  
MYSQL_HOST="192.168.124.6" # âœï¸ ä¿®æ”¹ä¸ºä½ çš„ MySQL IP  
MYSQL_USER="root" # è¯»å–æƒé™ç”¨æˆ·  
MYSQL_PASSWORD="123456" # ç”¨æˆ·å¯†ç   
MYSQL_DB="ams" # æ•°æ®åº“å

ELASTIC_PASSWORD="i*B4j6eD+g0e" # ES å¯†ç ï¼ˆè‡³å°‘ 8 ä½ï¼Œå«å¤§å°å†™+æ•°å­—ï¼‰

ES_VERSION="8.11.3" # å¿…é¡»ä¸ IK æ’ä»¶ç‰ˆæœ¬ä¸€è‡´  
LOGSTASH_VERSION="8.11.3"  
\# ========================================================

\# é¡¹ç›®è·¯å¾„  
ROOT_DIR="/project/elastic-sync"  
mkdir -p "$ROOT_DIR"  
cd "$ROOT_DIR"

echo "ğŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„"  
mkdir -p config/mysql config data/es data/kibana logs/logstash plugins/ik

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ä¸‹è½½ IK åˆ†è¯æ’ä»¶ &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;  
IK_URL="https://release.infinilabs.com/analysis-ik/stable/elasticsearch-analysis-ik-ik-${ES_VERSION}.zip"  
IK_DIR="$ROOT_DIR/plugins/ik"

if [ ! -f "$IK_DIR/plugin-descriptor.properties" ]; then  
echo "ğŸ“¥ æ­£åœ¨ä¸‹è½½ IK åˆ†è¯æ’ä»¶ v${ES_VERSION}&#8230;"  
wget -q "$IK_URL" -O /tmp/ik.zip  
unzip -q /tmp/ik.zip -d "$IK_DIR"  
rm /tmp/ik.zip  
chown -R 1000:1000 "$IK_DIR"  
echo "âœ… IK æ’ä»¶å®‰è£…å®Œæˆ"  
else  
echo "â„¹ï¸ IK æ’ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å®‰è£…"  
fi

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ç”Ÿæˆ elasticsearch.yml &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
cat > config/elasticsearch.yml << EOF  
cluster.name: production-cluster  
node.name: node-1  
node.roles: [ data, master, ingest ]

path:  
data: /usr/share/elasticsearch/data  
logs: /usr/share/elasticsearch/logs

network.host: 0.0.0.0  
http.port: 9200

http.cors.enabled: true  
http.cors.allow-origin: "*"

discovery.type: single-node

xpack.security.enabled: true  
xpack.security.http.ssl.enabled: false

xpack.monitoring.collection.enabled: true  
EOF

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ç”Ÿæˆ logstash.yml &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
cat > config/logstash.yml << EOF  
http.host: "0.0.0.0"  
xpack.monitoring.enabled: false  
config.reload.automatic: false  
EOF

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ç”Ÿæˆ logstash.conf &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
cat > config/logstash.conf << EOF  
input {  
jdbc {  
jdbc_connection_string => "jdbc:mysql://$MYSQL_HOST:3306/$MYSQL_DB?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai"  
jdbc_user => "$MYSQL_USER"  
jdbc_password => "$MYSQL_PASSWORD"  
jdbc_driver_library => "/usr/share/logstash/mysql/mysql-connector-java-8.0.30.jar"  
jdbc_driver_class => "com.mysql.cj.jdbc.Driver"

jdbc_default_timezone => "Asia/Shanghai"

statement => "  
SELECT * FROM article  
WHERE updated_at >= :sql_last_value  
ORDER BY updated_at ASC  
"

use_column_value => true  
tracking_column => "updated_at"  
tracking_column_type => "timestamp"  
last_run_metadata_path => "/usr/share/logstash/.logstash_jdbc_last_run"

schedule => "\*/2 \* \* \* *"  
}  
}

filter {

\# æ¸…æ´— content å­—æ®µä¸­çš„ HTML æ ‡ç­¾  
if [content] {  
mutate {  
gsub => [  
"content", "<[^>]*>", "" # åˆ é™¤æ‰€æœ‰ HTML æ ‡ç­¾ï¼š<p>ã€<div>ã€<span> ç­‰  
]  
}  
\# å¯é€‰ï¼šè¿›ä¸€æ­¥æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦  
mutate {  
gsub => [  
"content", "\s+", " " # å¤šä¸ªç©ºç™½å­—ç¬¦ï¼ˆç©ºæ ¼ã€æ¢è¡Œã€åˆ¶è¡¨ç¬¦ï¼‰åˆå¹¶ä¸ºä¸€ä¸ªç©ºæ ¼  
]  
}  
mutate {  
strip => ["content"] # å»é™¤é¦–å°¾ç©ºæ ¼  
}  
}

\# å¦‚æœ del_flag æ˜¯ 1ï¼Œæ ‡è®°è¯¥è®°å½•ç”¨äºåˆ é™¤  
if [del_flag] == 1 {  
mutate {  
add_tag => ["delete_document"]  
}  
}  
}

output {  
if "delete_document" in [tags] {  
elasticsearch {  
hosts => ["http://elasticsearch:9200"]  
user => "elastic"  
password => "$ELASTIC_PASSWOR"  
action => "delete"  
document_id => "%{id}"  
index => "articles"  
}  
} else {  
elasticsearch {  
hosts => ["http://elasticsearch:9200"]  
user => "elastic"  
password => "$ELASTIC_PASSWOR"  
index => "articles" # âœ… å›ºå®šç´¢å¼•  
document_id => "%{id}" # æ”¯æŒ varchar id  
doc_as_upsert => true # æ›´æ–°è¦†ç›–  
}  
}

stdout { codec => rubydebug }  
}  
EOF

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ç”Ÿæˆ docker-compose.yml &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
cat > docker-compose.yml << EOF  
services:  
elasticsearch:  
image: docker.elastic.co/elasticsearch/elasticsearch:$ES_VERSION  
container_name: elasticsearch  
environment:  
&#8211; discovery.type=single-node  
&#8211; ES_JAVA_OPTS=-Xms2g -Xmx2g  
&#8211; xpack.security.enabled=true  
&#8211; xpack.security.http.ssl.enabled=false  
&#8211; ELASTIC_PASSWORD=$ELASTIC_PASSWORD  
ports:  
&#8211; "9200:9200"  
volumes:  
&#8211; ./data/es:/usr/share/elasticsearch/data  
&#8211; ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml  
&#8211; ./plugins/ik:/usr/share/elasticsearch/plugins/ik  
networks:  
&#8211; elastic  
restart: unless-stopped  
healthcheck:  
test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]  
interval: 30s  
timeout: 10s  
retries: 3

kibana:  
image: docker.elastic.co/kibana/kibana:$LOGSTASH_VERSION  
container_name: kibana  
depends_on:  
elasticsearch:  
condition: service_healthy  
environment:  
&#8211; ELASTICSEARCH_HOSTS=["http://elasticsearch:9200"]  
&#8211; ELASTICSEARCH_USERNAME=elastic  
&#8211; ELASTICSEARCH_PASSWORD=$ELASTIC_PASSWORD  
&#8211; SERVER_NAME=kibana.example.com  
&#8211; I18N_LOCALE=zh-CN  
ports:  
&#8211; "5601:5601"  
volumes:  
&#8211; ./data/kibana:/usr/share/kibana/data  
networks:  
&#8211; elastic  
restart: unless-stopped

logstash:  
image: docker.elastic.co/logstash/logstash:$LOGSTASH_VERSION  
container_name: logstash  
depends_on:  
&#8211; elasticsearch  
volumes:  
&#8211; ./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf  
&#8211; ./config/logstash.yml:/usr/share/logstash/config/logstash.yml  
&#8211; ./logs/logstash:/var/log/logstash  
&#8211; ./config/mysql:/usr/share/logstash/mysql  
networks:  
&#8211; elastic  
restart: unless-stopped

networks:  
elastic:  
driver: bridge  
EOF

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ä¸‹è½½ MySQL JDBC é©±åŠ¨ &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
JDBC_JAR="config/mysql/mysql-connector-java-8.0.30.jar"  
if [ ! -f "$JDBC_JAR" ]; then  
echo "ğŸ“¥ ä¸‹è½½ MySQL JDBC é©±åŠ¨&#8230;"  
mkdir -p config/mysql  
wget -q https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.30/mysql-connector-java-8.0.30.jar -O "$JDBC_JAR"  
echo "âœ… JDBC é©±åŠ¨ä¸‹è½½å®Œæˆ"  
fi

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- è®¾ç½®æƒé™ &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
echo "ğŸ” è®¾ç½®ç›®å½•æƒé™"  
chown -R 1000:1000 data/es plugins/ik  
chmod -R 755 config logs  
chmod -R 777 data/kibana

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- ç”Ÿæˆåˆ›å»ºç´¢å¼•è„šæœ¬ &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
cat > create-index.sh << &#8216;EOF&#8217;  
#!/bin/bash  
echo "ğŸ”„ æ­£åœ¨åˆ›å»ºç´¢å¼• &#8216;articles&#8217; å¹¶é…ç½® IK åˆ†è¯å™¨&#8230;"

curl -X PUT "http://localhost:9200/articles" \  
-u elastic:$ELASTIC_PASSWORD \  
-H "Content-Type: application/json" \  
-d &#8216;  
{  
"settings": {  
"index": {  
"number_of_shards": 1,  
"number_of_replicas": 1  
},  
"analysis": {  
"analyzer": {  
"ik_analyzer": {  
"type": "custom",  
"tokenizer": "ik_max_word",  
"filter": ["lowercase"]  
}  
}  
}  
},  
"mappings": {  
"properties": {  
"id": { "type": "keyword" },  
"title": {  
"type": "text",  
"analyzer": "ik_max_word",  
"search_analyzer": "ik_smart"  
},  
"content": {  
"type": "text",  
"analyzer": "ik_max_word",  
"search_analyzer": "ik_smart"  
},  
"author": { "type": "keyword" },  
"created_at": { "type": "date" },  
"updated_at": { "type": "date" }  
}  
}  
}&#8217; && echo "âœ… ç´¢å¼• &#8216;articles&#8217; åˆ›å»ºæˆåŠŸï¼"  
EOF

chmod +x create-index.sh

\# &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- å®Œæˆ &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;-  
echo "=================================================="  
echo "ğŸ‰ éƒ¨ç½²å‡†å¤‡å®Œæˆï¼"  
echo "=================================================="  
echo ""  
echo "ğŸ“Œ ä¸‹ä¸€æ­¥æ“ä½œï¼š"  
echo "1. æ£€æŸ¥é…ç½®ï¼šnano setup-elastic-sync.sh ï¼ˆä¿®æ”¹ MySQL åœ°å€ã€ç”¨æˆ·ã€å¯†ç ï¼‰"  
echo "2. å¢åŠ æƒé™ï¼šchmod +x setup-elastic-sync.sh"  
echo "3. æ‰§è¡Œè„šæœ¬ï¼šsudo ./setup-elastic-sync.sh"  
echo "4. å¯åŠ¨æœåŠ¡ï¼šsudo docker compose up -d"  
echo "5. åˆ›å»ºç´¢å¼•ï¼šbash ./create-index.sh"  
echo "6. è®¿é—® Kibanaï¼šhttp://ä½ çš„æœåŠ¡å™¨IP:5601"  
echo " &#8211; ç”¨æˆ·ï¼šelastic"  
echo " &#8211; å¯†ç ï¼š$ELASTIC_PASSWORD"  
echo ""  
echo "ğŸ’¡ é¦–æ¬¡è¿è¡Œä¼šå…¨é‡åŒæ­¥ articles è¡¨ï¼Œä¹‹åæ¯ 2 åˆ†é’Ÿå¢é‡åŒæ­¥"  
echo "ğŸ” åœ¨ Kibana ä¸­æœç´¢ä¸­æ–‡ï¼ˆå¦‚â€œé˜¿é‡Œå·´å·´â€ï¼‰ï¼Œåº”èƒ½å‘½ä¸­ç»“æœ"  
echo ""  
echo "âš ï¸ æ³¨æ„ï¼šå¿…é¡»å…ˆè¿è¡Œ create-index.sh å†è®© Logstash å†™å…¥ï¼Œå¦åˆ™åˆ†è¯æ— æ•ˆï¼"

```

å¦‚æœ kibana ç”¨ elastic ç”¨æˆ·è¿ä¸ä¸Šï¼Œé€šè¿‡ Elasticsearch çš„ Security API ä¸ºå†…ç½®ç”¨æˆ· kibana_system ä¿®æ”¹å¯†ç ï¼š

```

curl -X POST "http://localhost:9200/_security/user/kibana_system/_password" -u elastic:i*B4j6eD+g0e -H "Content-Type: application/json" -d &#8216;{  
"password": "kibana_secure_password_2025"  
}&#8217;

```

ç„¶åä¿®æ”¹ docker-compose.yml ä¸­ kibana ä¿®æ”¹ç”¨æˆ·åï¼škibana_systemï¼Œå¯†ç ï¼škibana_secure_password_2025

å¦ Ubuntu å®‰è£… docker å‘½ä»¤ï¼š

```

\# å…³é˜²ç«å¢™ï¼ˆå¯é€‰ï¼‰  
sudo systemctl disable ufw  
sudo apt-get update  
sudo apt-get install apt-transport-https ca-certificates curl software-properties-common  
\# ä¸‹è½½å¹¶æ·»åŠ  Docker çš„ GPG å¯†é’¥  
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg &#8211;dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  
\# æ·»åŠ  Docker çš„ APT è½¯ä»¶æº  
echo "deb [arch=$(dpkg &#8211;print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

\# æ·»åŠ é˜¿é‡Œäº‘çš„ Docker GPG å¯†é’¥ï¼ˆå¯é€‰ï¼Œä¿¡ä»»æºï¼‰  
curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg &#8211;dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg  
\# ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæº  
echo "deb [arch=$(dpkg &#8211;print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update  
sudo apt-get install docker-ce docker-ce-cli containerd.io  
docker &#8211;version  
sudo systemctl is-enabled docker  
sudo systemctl enable docker  
sudo systemctl start docker  
sudo docker ps

```