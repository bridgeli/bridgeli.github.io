---
title: Hadoop集群搭建及运行初步
author: Bridge Li
type: post
date: 2015-06-28T14:18:20+00:00

duoshuo_thread_id:
  - 1.1604454626757E+18
categories:
  - 大数据
tags:
  - Big Data
  - Hadoop
  - Java

---
一直以来对Hadoop都非常有兴趣，所以这一段时间研究可以下Hadoop集群的搭建，今天写一篇小文章，主要是当做自己的笔记，因为写Hadoop怎么搭建的太多了，好了废话不多说，下面开始正文

一、环境准备

1. 系统环境

因为我个人比较喜欢Linux，另外很多资料都是基于Linux的，所以本文也不能例外，系统当然是Linux啦，开发是老夫最喜欢的Ubuntu，当然这个是看自己喜欢那个版本

2. 安装JDK

运行Hadoop需要jre环境，所以如果你的机器没有装JDK，那么就装吧，Ubuntu可以用apt-get install安装，也可以到这个地方：http://www.oracle.com/technetwork/java/javase/downloads/index.html下载然后安装，我个人比较喜欢后一种，因为这么我们可以自己选择装到哪个地方，有利于我们自己配JAVA_HOME、CLASSPATH以及PATH，配置如下：

```

vim /etc/profile

```

然后在里面添加：

```

export JAVA_HOME=/home/jdk1.7.0_40  
export CLASSPATH=".:$JAVA_HOME/lib:$CLASSPATH"  
export PATH="$JAVA_HOME/:$JAVA_HOME/bin:$PATH"

```

然后执行生效

```

source /etc/profile

```

我们可以任何目录下面测试JDK安装是否成功

3. 实现SSH无密码登陆

因为hadoop namenode要悄悄的SSH到各datanode中去启动相应的JVM进程，所以必须实现namenode能无密码登陆到datanode所在机器

配置命令如下：

```

sudo apt-get install ssh  
ssh-keygen -t rsa -P &#8221; -f ~/.ssh/id_rsa  
cat /home/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

```

可以用命令：

```

ssh localhost

```

检查是否配置成功，如果有提示授权成功等字样，则表示配置成功。

二、安装Hadoop

环境准备好之后，就要开始安装Hadoop，Hadoop有很多版本，我们是以hadoop-1.2.1为基础，首先下载Hadoop，下载地址：http://www.apache.org/dyn/closer.cgi/hadoop/common/，下载之后我们把它copy到/home下，解压：

```

tar -zxvf hadoop-1.2.1-bin.tar.gz

```

解压之后我们找到Hadoop的conf文件夹，下面我们的配置都将在这个文件夹下

1. 首先要配置的文件是：hadoop-env.sh，我们打开这个文件，找到配置JVAV_HOME的那一行，把注释打开，写上我们安装的JDK的路径

2. 配置core-site.xml，打开该文件，在文件中添加：

```

<configuration>

<property>  
<name>hadoop.tmp.dir</name>  
<value>/hadoop</value>  
</property>

<property>  
<name>dfs.name.dir</name>  
<value>/hadoop/name</value>  
</property>

<property>  
<name>fs.default.name</name>  
<value>hdfs://localhost:9000</value>  
</property>

</configuration>

```

3. 配置hdfs-site.xml，同样添加：

```

<configuration>  
<property>  
<name>dfs.data.dir</name>  
<value>/hadoop/data</value>  
</property>  
</configuration>

```

4. 配置mapred-site.xml，也是添加

```

<configuration>  
<property>  
<name>mapred.job.tracker</name>  
<value>localhost:9001</value>  
</property>  
</configuration>

```

5. 下面我们同样需要配置hadoop_home，同样是打开

```

vim /etc/profile

```

在里面添加：

```

export HADOOP_HOME=/home/ae/hadoop-1.2.1  
export PATH=$PATH:$HADOOP_HOME/bin

```

然后同样让它生效

```

source /etc/profile

```

6. 格式化namenode

Hadoop在运行之前，我们需要对namenode进行格式化操作，因为我们配置了hadoop_home，所以可以在任意目录下执行：

```

hadoop namenode -format

```

7. 启动Hadoop

```

start-all.sh

```

然后我们就可以执行以下命令，看有哪些Java进程：

```

jps

```

如果看到以下进程，则表示启动成功：

```

7085 JobTracker  
7329 Jps  
6824 DataNode  
7259 TaskTracker  
6647 NameNode  
7001 SecondaryNameNode

```

如果想停止Hadoop集群，我们可以用以下命令：

```

stop-all.sh

```

好了，到此为止呢，Hadoop集群的搭建就完成了，当然这只是一个伪分布式环境的搭建，一方面是因为老夫手里并没有多台电脑，但老夫相信多台电脑的搭建和一台应该是很相似的，看这篇文章的人，相信都有举一反三的能力，接下来老夫会写一篇Hadoop版的“hello word”：“word count”的应用程序以及hdfa的使用。

参考资料：  
1. http://www.diguage.com/archives/53.html  
2. http://115.29.142.55/how-to-build-hadoop-distributed-environment.html